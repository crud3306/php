  
高并发  
-------------
并发：在某个时间点，有多少个访问同时到来。高并发，则指这种并发数特别大。  
  
通常如果一个系统的日pv在千万以上，有可能是一个高并发系统。为什么说是可能，因为有的公司完全不走技术路线，全靠机器堆，这不在我们的讨论范围。  
  
  
高并发的问题，我们具体该关心什么？  
-------------
qps：每秒种请求或者查询的数量，在互联网领域，指每秒响应请求数(指http请求)。  
吞吐量：单位时间内处理的请求数量（通常由qps与并发数决定）  
响应时间：从请求发出到收到响应花费的时间。例如系统处理一个http请求需要100ms，这个100ms就是系统的响应时间。  
pv：综合浏览量（page view），即页面浏览量或点击量，一个访客在24小时内访问的页面数量。同一个人浏览某网站的同一页面，只记作一次pv。  
uv：独立访客（unique visitor），即一定时间范围内相同访客多次访问网站，只计算为1个独立访客  
  
带宽：计算带完大小需关注两个指标，峰值流量和页面的平均大小。  
日网站带宽 = pv / 统计时间(换算到秒 3600*24) * 平均页面大小(单位kb) * 8  
峰值一般是平均值的倍数，根据实际情况来定  
  
二八定律：80%的访问量集中在20%的时间内  
(总pv数 * 80%) / (6小时秒数 * 20%) = 峰值每秒请求数(qps)  
为什么是6个小时，是做的简单估计 比如：中午2小时，下午2小时间，晚上2小时  
  
  
注意：  
qps不等于并发连接数  
qps是每秒http请求数量，并发连接数是系统同时处理的请求数量(一个并发连接数里面有可能有多个http请求，比如我们请求 一个网页，可发现一个页面请求中可能有多个http请求)  
  
  
  
  
压力测试  
-------------
测试能承受的最大并发、最大承受的qps。  
压力测试可测出某台服务器最大能够承爱多少qps  
而网站一天的pv数，通过二八定律计算出峰值qps  
对比两个值   
  
不是说仅频感觉到网站的请求量比较大了，这时候进行优化，我们需要拿一定的相关依据。  
  
  
我需要知道整个网站的日qps峰值是多少，单台服务器的qps承受能力是多少。  
  
  
常用性能测试工具：  
ab，wrk，http_load，web bench，siege，apache jmeter  
  
  
ab  
-------------
ab全称：apache benchmark，是apache官方推出的工具。它的工作原理是创建多个并发访问线程，模拟多个访问者同时对某一url地址进行访问。它的测试目标是基于url的。因此，它即能测试apache的负载压力，也能测试nginx，tomcat等其它web服务器的压力。  
  
安装：  
yum install httpd-tools  
  
模拟并发请求100次，总共请求5000次  
ab -c 100 -n 5000 待测网址  
  
测试注意事项：  
测试机器与被测试机器分开，别在一台机子上测  
不要对线上服务做压力测试  
观察测试工具ab所在机器，以及被测试的前端机的cpu、内存、网络等都不超过最高限度的75%。  
  
对于qps的测试，不仅要考虑服务器的相关性能，也要考虑程序的相关优化。比如访问一个静态html页面，qps会非常高，访问一段业务较复杂的php，则qps会很低。所以需要不断有ab测试，保证成功率在95%以上。  
  
qps达到极限  
随着qps的增长，每个阶段需要根据实际情况来进行优化，优化的方案也与硬件条件、网络带宽息息相关。  

比如：  
  
50QPS以下 -- 小网站  
没什么好说的，简单的小网站而已，你可以用最简单的方法快速搭建，短期没有太多的技术瓶颈，只要服务器不要太烂就好。   
  
  
50～100QPS -- DB极限型  
qps达到100  
大部分的关系型数据库的每次请求大多都能控制在0.01秒左右，即便你的网站每页面只有一次DB请求，那么如果页面请求无法保证在1秒钟内完成100个请求，这个阶段要考虑做Cache或者多DB负载。无论那种方案，网站重构是不可避免的。  
方案：数据库缓存层、数据库的负载均衡  
  

300～800QPS -- 带宽极限型  
qps达到800  
目前服务器大多用了IDC提供的“百兆带宽”，这意味着网站出口的实际带宽是8MByte左右。假定每个页面只有10KByte，在这个并发条件下，百兆带宽已经吃完。首要考虑是CDN加速／异地缓存，多机负载等技术。  
方案：cdn加速、负载均衡  
  
  
500～1000QPS -- 内网带宽极限＋Memcache极限型   
qps达到1000   
假设使用memcache缓存数据库查询数据，每个页面对memcache的请求远大于直接对db的请求。  
memcache的悲观并发数在2w左右，看似很高，但有可能在之前内网带宽已经吃光，表现出不稳定，可能直接将压力转嫁到了DB层上，这就最终导致整个系统在达到某个阀值之上，性能迅速下滑。   
方案：静态html缓存  
  
  
1000～2000QPS -- FORK/SELECT，锁模式极限型  
qps达到2000  
一句话：线程模型决定吞吐量。不管你系统中最常见的锁是什么锁，这个级别下，文件系统访问锁都成为了灾难。这就要求系统中不能存在中央节点，所有的数据都必须分布存储，数据需要分布处理。  
方案：做业务分离，分布式存储  
  
2000QPS以上 -- C10K极限  
尽管现在很多应用已经实现了C25K，但短板理论告诉我们，决定网站整体并发的永远是最低效的那个环节。我承认我生涯中从未遇到过2000QPS以上，甚至1.5K以上的网站，希望有此经验的哥们可以一起交流下  
  
  
高并发解决方案案例：  
-------------
流量优化  
防盗链处理  
  
前端优化  
减少http请求(比如图片、css、js等做合并、压缩)  
添加异步请求  
长页页图片的延迟加载  
启用浏览缓存和文件压缩  
cdn加速  
建立独立图片服务器（因图片比较吃io的，然后针对图片服务器做优化，比如对硬盘的转速进行提高，图片服务做集群）  
  
服务端优化  
页面静态化（实时性要求比较高的除外）  
并发处理（多进程、多线程异步处理）  
队列处理  
  
数据库优化  
数据库缓存  
分库分表、分区操作  
读写分离  
负载均衡  
  
web服务器优化  
负载均衡(nginx upstream)  
  
  




































